name: Scrape

on:
  schedule:
    - cron: '42 3 * * *'
  workflow_dispatch: {}

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: scrape
  cancel-in-progress: true

jobs:
  scrape:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-22.04
    steps:
      - uses: actions/checkout@v3.0.2
      - uses: denoland/setup-deno@v1.1.0
        with:
          deno-version: 1.24.2
      - run: make load-cache
      - run: deno run --lock=lock.json --cached-only --no-remote --import-map=vendor/import_map.json --allow-net --allow-write src/cli.ts everything.json
      - uses: actions/upload-artifact@v3.1.0
        with:
          name: everything.json
          path: everything.json
      - run: mkdir site && mv everything.json site/
      - uses: actions/configure-pages@v1
      - uses: actions/upload-pages-artifact@v1
        with:
          path: site
      - uses: actions/deploy-pages@main
        id: deployment
